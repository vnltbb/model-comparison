{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a58edd",
   "metadata": {},
   "source": [
    "## data split\n",
    "### import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a723ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794eb91",
   "metadata": {},
   "source": [
    "### dir settingğŸ”§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATASET_DIR = \"/Volumes/PortableSSD/data\" \n",
    "BASE_OUTPUT_DIR = \"/Users/vnlt/PROJECT/1st-experimet-tf/split_dataset/No-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba928b2",
   "metadata": {},
   "source": [
    "### ratio setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5ed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í´ë˜ìŠ¤ë³„ ë™ì¼ ê°œìˆ˜ë¡œ ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ. ê²½ë¡œ: /Users/vnlt/PROJECT/1st-experimet-tf/split_dataset/No-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. ê° í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ íŒŒì•…\n",
    "class_image_counts = []\n",
    "for cls in os.listdir(ORIGINAL_DATASET_DIR):\n",
    "    cls_path = os.path.join(ORIGINAL_DATASET_DIR, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    images = os.listdir(cls_path)\n",
    "    class_image_counts.append(len(images))\n",
    "\n",
    "min_count = min(class_image_counts)  # ëª¨ë“  í´ë˜ìŠ¤ ì¤‘ ìµœì†Œ ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "\n",
    "# 2. ê° í´ë˜ìŠ¤ë³„ë¡œ min_countë§Œí¼ë§Œ ëœë¤ ìƒ˜í”Œë§ í›„ ë¶„í• \n",
    "for cls in os.listdir(ORIGINAL_DATASET_DIR):\n",
    "    cls_path = os.path.join(ORIGINAL_DATASET_DIR, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(cls_path)\n",
    "    np.random.shuffle(images)\n",
    "    images = images[:min_count]  # ìµœì†Œ ê°œìˆ˜ë§Œí¼ë§Œ ì‚¬ìš©\n",
    "\n",
    "    train_imgs, temp_imgs = train_test_split(images, train_size=train_ratio)\n",
    "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=test_ratio/(val_ratio+test_ratio))\n",
    "\n",
    "    for category, category_imgs in zip(['train', 'val', 'test'], [train_imgs, val_imgs, test_imgs]):\n",
    "        save_path = os.path.join(BASE_OUTPUT_DIR, category, cls)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        for img in category_imgs:\n",
    "            shutil.copy(os.path.join(cls_path, img), os.path.join(save_path, img))\n",
    "\n",
    "print(\"âœ… í´ë˜ìŠ¤ë³„ ë™ì¼ ê°œìˆ˜ë¡œ ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ. ê²½ë¡œ:\", BASE_OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
